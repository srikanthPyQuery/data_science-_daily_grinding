{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ea13b4-4f8d-40ee-b223-96c1bfaa0ed2",
   "metadata": {},
   "source": [
    "# MAR_Missing At Random\n",
    "\n",
    "### Missingness depends on other observed variables, NOT on the missing value itself.\n",
    "### It’s less restrictive than MCAR (Missing Completely At Random) but more manageable than MNAR (Missing Not At Random).\n",
    "\n",
    "### Understand with examples:\n",
    "##### Suppose income data is missing more often for younger people,students, certain job roles . i.e: The missingness depends on age/job (observed), not on the true income (unobserved). , (Younger respondents less likely to report income)\n",
    "##### MCAR: Missingness happens randomly during collection, transfer, or analysis — independent of the data itself.\n",
    "##### MAR: Missingness happens systematically, because the source’s response depends on other observed variables (not on the missing value itself).\n",
    "#### - In this type of missingness, the likelihood of a value being missing is influenced by other observed variables. Since the missing values are related to existing data, simple imputation methods (like mean, median,random sampling and mode) are not ideal, as they ignore these **dependencies** and can distort the existing **relationships** in the dataset.\n",
    "#### - So,always consider the other related variable to predict missing value\n",
    "##### For above Income we can model missingness using Age as a predictor in imputation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3861b00-80b5-4db2-99ac-29348bf9dda0",
   "metadata": {},
   "source": [
    "## Imputations for MAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca955448-db7b-45ab-8d46-19215399f35d",
   "metadata": {},
   "source": [
    "### 1. Group-based imputation (Simple MAR baseline)\n",
    "##### Ex: df['Income'] = df.groupby('Age')['Income'] \\.transform(lambda x: x.fillna(x.median()))\n",
    "##### Instead of imputing missing income with the overall median, you impute median within each age group, \n",
    "##### - Cons : Loss of variability,Bias if group is small, Ignores other predictors, Not suitable for predictive modeling\n",
    "#####  Manual feature selection\n",
    "##### Applicable : Small data, clear groups, Clear categorical driver of missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3ba1d-d13d-42a6-a4d2-a71c0be18654",
   "metadata": {},
   "source": [
    "### 2. Regression Imputation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "train = df[df['Income'].notna()]\n",
    "test  = df[df['Income'].isna()]\n",
    "\n",
    "X_train = train[['Age', 'Experience']]\n",
    "\n",
    "y_train = train['Income']\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "df.loc[df['Income'].isna(), 'Income'] = model.predict(  test[['Age', 'Experience']])\n",
    "\n",
    "#### - Pros : \n",
    "Unlike mean/median imputation, this method preserves relationships between variables.\n",
    "keeps variability\n",
    "More realistic if predictors explain Income well.\n",
    "Used for Complex Datasets\n",
    "#### - Cons : \n",
    "Assumes a linear relationship between predictors and Income.\n",
    "If the model is poorly fitted, imputations may be inaccurate.\n",
    "Sensitive to outliers in training data.\n",
    "##### Group‑median imputation is simple but flattens values within groups. Regression imputation is richer, uses multiple predictors, and preserves variability — but depends on model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faff662-7897-49e2-8322-95f68d89fbfb",
   "metadata": {},
   "source": [
    "### 3. KNN Imputation\n",
    "#### Fill missing value using similar rows.\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "df_knn = pd.DataFrame(\n",
    "    imputer.fit_transform(df[numerical_features]),\n",
    "    columns=numerical_features,\n",
    "    index=df.index)\n",
    "##### Creates a K‑Nearest Neighbors imputer.\n",
    "##### For each missing value, it looks at the 5 nearest rows (neighbors) based on other numerical features.\n",
    "##### The missing value is replaced with the average of those neighbors’ values.\n",
    "##### Returns a NumPy array with missing values filled in. Thats why we again convert them in to Data Frame, ensuring column names and index aligns with original dataset\n",
    "#### - Pros :\n",
    "Preserves relationships\n",
    "Different missing values can be imputed differently depending on their neighbors.\n",
    "Unlike mean/median imputation, it maintains variability and local patterns.\n",
    "#### - Cons:\n",
    "For large datasets, finding neighbors can be slow.                              \n",
    "If *n_neighbors* Too small → noisy imputations; too large → values converge toward global mean.\n",
    "\n",
    "Only works with numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af34172-65e1-4147-ad6f-b7266dabdc7f",
   "metadata": {},
   "source": [
    "### 4. Iterative Imputer - Multiple Imputation by Chained Equations (MICE)\n",
    "#### Predict each missing feature using others\n",
    "#### Iterate until convergence\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer( estimator=LinearRegression(),\n",
    "    max_iter=10,\n",
    "    random_state=42)\n",
    "\n",
    "df_mice = pd.DataFrame(\n",
    "    imputer.fit_transform(df[numerical_features]),\n",
    "    columns=numerical_features,\n",
    "    index=df.index)\n",
    "##### cycles through all features with missing values up to 10 times, refining imputations each round.\n",
    "##### Setting random_state=42 fixes the random number generator’s seed, ensuring that the imputation process is reproducible.Without it, each run could produce slightly different imputed values, even on the same dataset.\n",
    "\n",
    "#### - Pros:\n",
    "- Multivariate approach: Unlike mean/median or group imputation, it uses all other features to predict missing values.\n",
    "- Iterative refinement: Each round improves imputations by re‑using updated values.\n",
    "- *Flexibility*: You can swap out LinearRegression() for other estimators (e.g., DecisionTreeRegressor, BayesianRidge).\n",
    "- A well‑established statistical method.\n",
    "#### - Cons:\n",
    "- Iterative cycles can be slow for large datasets.\n",
    "- Linear regression may not capture nonlinear relationships.\n",
    "- Sensitive to collinearity/outliers: Regression can be distorted if predictors are highly correlated or extreme.\n",
    "##### A more sophisticated alternative to mean/median or KNN imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978275b3-db39-4c42-9e95-fd2763478817",
   "metadata": {},
   "source": [
    "### 5. Multiple Imputation (Advanced, Statistical)\n",
    "\n",
    "##### Idea:\n",
    "\n",
    "##### Create multiple imputed datasets\n",
    "\n",
    "##### Combine estimates\n",
    "\n",
    "#### More common in biostatistics, less in ML pipelines because of complexity and computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40865d-7e05-4929-8168-820d0ca4b9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "799c9a04-8cc9-42e1-ab2b-e33971ec5f45",
   "metadata": {},
   "source": [
    "\n",
    "| Scenario                    | Best choice       |\n",
    "| --------------------------- | ----------------- |\n",
    "| Small data, clear groups    | Group median      |\n",
    "| Linear relationships        | Regression        |\n",
    "| Non-linear, local structure | KNN               |\n",
    "| Complex dependencies        | Iterative Imputer |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
